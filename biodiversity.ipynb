{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biodiversity Project\n",
    "For this project, we will interpret data from the National Parks Service about endangered species in different parks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import needed modules\n",
    "The next cell will hold the modules that we will use in the course of this data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Describing the data\n",
    "A good starting point for every DataScience project. We need to check what we actually have available.\n",
    "Both `Observations.csv` and `Species_info.csv` was provided by [Codecademy.com](https://www.codecademy.com).\n",
    "Once we understand the data at our disposal, we can start formulating questions that we can answer with this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codecademy has provided 2 CSV files\n",
    "# Start by loading them usinf Pandas\n",
    "observations = pd.read_csv(\"./biodiversity_starter/observations.csv\")\n",
    "species_info = pd.read_csv(\"./biodiversity_starter/species_info.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiecies_info\n",
    "I will focus first on describing the contents of spiecies_info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['category', 'scientific_name', 'common_names', 'conservation_status'], dtype='object')\n",
      "category               object\n",
      "scientific_name        object\n",
      "common_names           object\n",
      "conservation_status    object\n",
      "dtype: object\n",
      "              category    scientific_name        common_names  \\\n",
      "count             5824               5824                5824   \n",
      "unique               7               5541                5504   \n",
      "top     Vascular Plant  Castor canadensis  Brachythecium Moss   \n",
      "freq              4470                  3                   7   \n",
      "\n",
      "       conservation_status  \n",
      "count                  191  \n",
      "unique                   4  \n",
      "top     Species of Concern  \n",
      "freq                   161  \n",
      "  category                scientific_name  \\\n",
      "0   Mammal  Clethrionomys gapperi gapperi   \n",
      "1   Mammal                      Bos bison   \n",
      "2   Mammal                     Bos taurus   \n",
      "3   Mammal                     Ovis aries   \n",
      "4   Mammal                 Cervus elaphus   \n",
      "5   Mammal         Odocoileus virginianus   \n",
      "6   Mammal                     Sus scrofa   \n",
      "7   Mammal                  Canis latrans   \n",
      "8   Mammal                    Canis lupus   \n",
      "9   Mammal                    Canis rufus   \n",
      "\n",
      "                                        common_names conservation_status  \n",
      "0                           Gapper's Red-Backed Vole                 NaN  \n",
      "1                              American Bison, Bison                 NaN  \n",
      "2  Aurochs, Aurochs, Domestic Cattle (Feral), Dom...                 NaN  \n",
      "3  Domestic Sheep, Mouflon, Red Sheep, Sheep (Feral)                 NaN  \n",
      "4                                      Wapiti Or Elk                 NaN  \n",
      "5                                  White-Tailed Deer                 NaN  \n",
      "6                                Feral Hog, Wild Pig                 NaN  \n",
      "7                                             Coyote  Species of Concern  \n",
      "8                                          Gray Wolf          Endangered  \n",
      "9                                           Red Wolf          Endangered  \n"
     ]
    }
   ],
   "source": [
    "print(species_info.columns) # Which columns are available.\n",
    "print(species_info.dtypes) # Which types of data. Does this make sense?\n",
    "print(species_info.describe()) # short summary statistics\n",
    "print(species_info.head(10)) # and visualy check the first 10 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that this is a table on all the spiecies that we will have observations from. Included are category, scientific name, common names, and conservation status. The collumn conservation status contains NaN values, which might indicate species of least concern.\n",
    "\n",
    "We will now dive a bit deeper into the collumns of the Species info csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleanup.\n",
    "One of the points of attention in spiecies info is that there is a count of 5824 scientific_names reported, but only 5541 of them are unique. As suposedly species name is unique, let us investigate what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     category         scientific_name                          common_names  \\\n",
      "3017   Mammal          Cervus elaphus                    Rocky Mountain Elk   \n",
      "3019   Mammal  Odocoileus virginianus  White-Tailed Deer, White-Tailed Deer   \n",
      "3020   Mammal             Canis lupus                       Gray Wolf, Wolf   \n",
      "3022   Mammal           Puma concolor           Cougar, Mountain Lion, Puma   \n",
      "3025   Mammal        Lutra canadensis                           River Otter   \n",
      "\n",
      "     conservation_status  \n",
      "3017                 NaN  \n",
      "3019                 NaN  \n",
      "3020         In Recovery  \n",
      "3022                 NaN  \n",
      "3025                 NaN  \n"
     ]
    }
   ],
   "source": [
    "print(species_info[species_info.duplicated(subset=\"scientific_name\")].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know that a _Cervus elaphus_ and _Puma concolor_ are posted at least twice. Let us inspect the entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     category scientific_name        common_names conservation_status\n",
      "4      Mammal  Cervus elaphus       Wapiti Or Elk                 NaN\n",
      "3017   Mammal  Cervus elaphus  Rocky Mountain Elk                 NaN\n",
      "     category scientific_name                 common_names conservation_status\n",
      "16     Mammal   Puma concolor      Panther (Mountain Lion)                 NaN\n",
      "3022   Mammal   Puma concolor  Cougar, Mountain Lion, Puma                 NaN\n",
      "4451   Mammal   Puma concolor                Mountain Lion                 NaN\n"
     ]
    }
   ],
   "source": [
    "print(species_info[species_info.apply(lambda row: row[\"scientific_name\"]==\"Cervus elaphus\", axis=1)])\n",
    "print(species_info[species_info.apply(lambda row: row[\"scientific_name\"]==\"Puma concolor\", axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that more common names of the same spiecies turned up, and instead of adding to the old entry, somebody created a new one. We can join the enties together, and delete the duplicates to get a cleaner dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(dataframe, key_column, property_column):\n",
    "    \"\"\"Function to clean up a dataframe.\n",
    "     One column is supposed to be the key_column, while a second one holds properies for that key.\n",
    "     In case of a duplicate entry in the key collumn:\n",
    "      properties are added to the first instance, and the second instance is dropped.\n",
    "    This is repeated until no more duplicates are found.\n",
    "    \"\"\"\n",
    "    cleaned = False\n",
    "    while not cleaned:\n",
    "        duplicated = dataframe[dataframe.duplicated(subset=key_column)]\n",
    "        if duplicated.shape[0] == 0:\n",
    "            cleaned = True\n",
    "        else:\n",
    "            key = duplicated.iloc[0][key_column]\n",
    "            label = duplicated.index[0]\n",
    "            entry = duplicated.iloc[0][property_column]\n",
    "            label2 = dataframe[dataframe.apply(lambda row: row[key_column]==key, axis=1)].index[0]\n",
    "            dataframe.loc[label2, property_column] += \", \" + entry\n",
    "            dataframe = dataframe.drop(label)\n",
    "            \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "species_cleaned = cleanup(species_info, \"scientific_name\", \"common_names\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of species: 7 \n",
      "\n",
      "List of species present in the survey: ['Mammal' 'Bird' 'Reptile' 'Amphibian' 'Fish' 'Vascular Plant'\n",
      " 'Nonvascular Plant'] \n",
      "\n",
      "Distribution of species amongst categories: \n",
      "category\n",
      "Amphibian              79\n",
      "Bird                  488\n",
      "Fish                  125\n",
      "Mammal                176\n",
      "Nonvascular Plant     333\n",
      "Reptile                78\n",
      "Vascular Plant       4262\n",
      "dtype: int64\n",
      "\n",
      "Distribution in percentage of total spiecies:\n",
      "category\n",
      "Amphibian             1.425735\n",
      "Bird                  8.807075\n",
      "Fish                  2.255910\n",
      "Mammal                3.176322\n",
      "Nonvascular Plant     6.009746\n",
      "Reptile               1.407688\n",
      "Vascular Plant       76.917524\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of species: {species_cleaned.category.nunique()} \\n\")\n",
    "print(f\"List of species present in the survey: {species_cleaned.category.unique()} \\n\")\n",
    "print(\"Distribution of species amongst categories: \")\n",
    "print(species_cleaned.groupby(\"category\").size())\n",
    "print(\"\")\n",
    "print(\"Distribution in percentage of total spiecies:\")\n",
    "print(species_cleaned.groupby(\"category\").size()/species_cleaned.category.size*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that of all the species tracked, the vast majority (76.9%) are _vascular plants_. _Birds_ are a distant second with almost 9%.\n",
    "\n",
    "A first thing to investigate would be to see if the same percantages are reflected in conservation satus, or if that is skewed towards other types of species.\n",
    "In order to do so, we will replace the NaN with _least_concern_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5 types of conservation status.\n",
      "They are: ['least_concern' 'Species of Concern' 'Endangered' 'Threatened'\n",
      " 'In Recovery']\n"
     ]
    }
   ],
   "source": [
    "species_cleaned.conservation_status.fillna(\"least_concern\", inplace=True)\n",
    "print(f\"There are {species_cleaned.conservation_status.nunique()} types of conservation status.\")\n",
    "print(f\"They are: {species_cleaned.conservation_status.unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, how does this play out amongst categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>category</th>\n",
       "      <th>Amphibian</th>\n",
       "      <th>Bird</th>\n",
       "      <th>Fish</th>\n",
       "      <th>Mammal</th>\n",
       "      <th>Nonvascular Plant</th>\n",
       "      <th>Reptile</th>\n",
       "      <th>Vascular Plant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conservation_status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Endangered</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In Recovery</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Species of Concern</th>\n",
       "      <td>4.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threatened</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>least_concern</th>\n",
       "      <td>72.0</td>\n",
       "      <td>413.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4216.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "category             Amphibian   Bird   Fish  Mammal  Nonvascular Plant  \\\n",
       "conservation_status                                                       \n",
       "Endangered                 1.0    4.0    3.0     6.0                NaN   \n",
       "In Recovery                NaN    3.0    NaN     NaN                NaN   \n",
       "Species of Concern         4.0   68.0    4.0    22.0                5.0   \n",
       "Threatened                 2.0    NaN    3.0     2.0                NaN   \n",
       "least_concern             72.0  413.0  115.0   146.0              328.0   \n",
       "\n",
       "category             Reptile  Vascular Plant  \n",
       "conservation_status                           \n",
       "Endangered               NaN             1.0  \n",
       "In Recovery              NaN             NaN  \n",
       "Species of Concern       5.0            43.0  \n",
       "Threatened               NaN             2.0  \n",
       "least_concern           73.0          4216.0  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conservation_status = species_cleaned.groupby([\"conservation_status\", \"category\"])[\"scientific_name\"].count().unstack()\n",
    "\n",
    "conservation_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit too much info to process easily.\n",
    "In order to clarify things, we will simplify the data to two possible status: Protected and not Protected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unprotected and Protected # of species per category\n",
      "is_protected       False  True \n",
      "category                       \n",
      "Amphibian             72      7\n",
      "Bird                 413     75\n",
      "Fish                 115     10\n",
      "Mammal               146     30\n",
      "Nonvascular Plant    328      5\n",
      "Reptile               73      5\n",
      "Vascular Plant      4216     46\n",
      "\n",
      "Unprotected and Protected % of species per category\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>is_protected</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amphibian</th>\n",
       "      <td>91.139241</td>\n",
       "      <td>8.860759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bird</th>\n",
       "      <td>84.631148</td>\n",
       "      <td>15.368852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fish</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mammal</th>\n",
       "      <td>82.954545</td>\n",
       "      <td>17.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonvascular Plant</th>\n",
       "      <td>98.498498</td>\n",
       "      <td>1.501502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reptile</th>\n",
       "      <td>93.589744</td>\n",
       "      <td>6.410256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vascular Plant</th>\n",
       "      <td>98.920695</td>\n",
       "      <td>1.079305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "is_protected           False      True \n",
       "category                               \n",
       "Amphibian          91.139241   8.860759\n",
       "Bird               84.631148  15.368852\n",
       "Fish               92.000000   8.000000\n",
       "Mammal             82.954545  17.045455\n",
       "Nonvascular Plant  98.498498   1.501502\n",
       "Reptile            93.589744   6.410256\n",
       "Vascular Plant     98.920695   1.079305"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_cleaned[\"is_protected\"] = species_cleaned[\"conservation_status\"] != \"least_concern\"\n",
    "\n",
    "print(\"Unprotected and Protected # of species per category\")\n",
    "print(species_cleaned.groupby([\"category\",  \"is_protected\"])[\"scientific_name\"].count().unstack())\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Unprotected and Protected % of species per category\")\n",
    "(species_cleaned.groupby([\"category\",  \"is_protected\"])[\"scientific_name\"].count()/(species_cleaned.groupby(\"category\").size())*100).unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as a first point, it seems that Birds and Mammals with 15% and 17% of protected spiecies are doing the worst. Next is the group containing Amhibians, Fish, and Reptiles. Both Vascular and Nonvascular plants seem to be the least affected types of spiecies.\n",
    "To see if these differences are actually significant and the groups well defined, we will calculate the P value for:\n",
    "Mamal vs. Bird, Mammal vs. Fish, Fish vs. Reptile, Fish vs. Nonvascular Plant.\n",
    "We expect no significal difference for Mamal vs. Bird or Fish vs. Reptile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_values smaller than 0.05 are typically considered indicators of a significant difference.\n",
      "The p_value for a chi2 difference between Mammals and Birds is: 0.6875948096661336.\n",
      "The p_value for a chi2 difference between Mammals and Fish is: 0.03521990485242024.\n",
      "The p_value for a chi2 difference between Reptiles and Fish is: 0.8844187103100194.\n",
      "The p_value for a chi2 difference between Nonvascular plants and Fish is: 0.0014420708083000965.\n"
     ]
    }
   ],
   "source": [
    "_, p_value, _, _ = chi2_contingency([[30, 146],[75, 413]])\n",
    "print(\"P_values smaller than 0.05 are typically considered indicators of a significant difference.\")\n",
    "print(f\"The p_value for a chi2 difference between Mammals and Birds is: {p_value}.\")\n",
    "\n",
    "_, p_value, _, _ = chi2_contingency([[30, 146],[10, 115]])\n",
    "print(f\"The p_value for a chi2 difference between Mammals and Fish is: {p_value}.\")\n",
    "\n",
    "_, p_value, _, _ = chi2_contingency([[5, 73],[10, 115]])\n",
    "print(f\"The p_value for a chi2 difference between Reptiles and Fish is: {p_value}.\")\n",
    "\n",
    "_, p_value, _, _ = chi2_contingency([[5, 328],[10, 115]])\n",
    "print(f\"The p_value for a chi2 difference between Nonvascular plants and Fish is: {p_value}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we judged the categories correctly, and the calculated p_values support our three groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "Now it is time to turn our attention to the observation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['scientific_name', 'park_name', 'observations'], dtype='object')\n",
      "scientific_name    object\n",
      "park_name          object\n",
      "observations        int64\n",
      "dtype: object\n",
      "       observations\n",
      "count  23296.000000\n",
      "mean     142.287904\n",
      "std       69.890532\n",
      "min        9.000000\n",
      "25%       86.000000\n",
      "50%      124.000000\n",
      "75%      195.000000\n",
      "max      321.000000\n",
      "                     scientific_name                            park_name  \\\n",
      "0                 Vicia benghalensis  Great Smoky Mountains National Park   \n",
      "1                     Neovison vison  Great Smoky Mountains National Park   \n",
      "2                  Prunus subcordata               Yosemite National Park   \n",
      "3               Abutilon theophrasti                  Bryce National Park   \n",
      "4           Githopsis specularioides  Great Smoky Mountains National Park   \n",
      "5  Elymus virginicus var. virginicus               Yosemite National Park   \n",
      "6                   Spizella pusilla            Yellowstone National Park   \n",
      "7                  Elymus multisetus  Great Smoky Mountains National Park   \n",
      "8             Lysimachia quadrifolia               Yosemite National Park   \n",
      "9         Diphyscium cumberlandianum            Yellowstone National Park   \n",
      "\n",
      "   observations  \n",
      "0            68  \n",
      "1            77  \n",
      "2           138  \n",
      "3            84  \n",
      "4            85  \n",
      "5           112  \n",
      "6           228  \n",
      "7            39  \n",
      "8           168  \n",
      "9           250  \n"
     ]
    }
   ],
   "source": [
    "print(observations.columns) # Which columns are available.\n",
    "print(observations.dtypes) # Which types of data. Does this make sense?\n",
    "print(observations.describe()) # short summary statistics\n",
    "print(observations.head(10)) # and visualy check the first 10 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a column indicating the scientific name of the spiecies observed, another is the name of the park, and last is how many of those spiecies were observed in said park.\n",
    "\n",
    "We can see which park has the most observation of spiecies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "park_name\n",
       "Bryce National Park                     576025\n",
       "Great Smoky Mountains National Park     431820\n",
       "Yellowstone National Park              1443562\n",
       "Yosemite National Park                  863332\n",
       "Name: observations, dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.groupby(\"park_name\")[\"observations\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "park_name\n",
       "Bryce National Park                    5824\n",
       "Great Smoky Mountains National Park    5824\n",
       "Yellowstone National Park              5824\n",
       "Yosemite National Park                 5824\n",
       "Name: scientific_name, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations.groupby([\"park_name\"])[\"scientific_name\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, in each park we have 5824 observations, while there are only 5541 unique species names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of duplicated observations in each park:\n",
      "park_name\n",
      "Bryce National Park                    274\n",
      "Great Smoky Mountains National Park    274\n",
      "Yellowstone National Park              274\n",
      "Yosemite National Park                 274\n",
      "dtype: int64\n",
      "\n",
      "Are some species duplicated more than once? Let us see the maximum duplication number.\n",
      "3\n",
      "\n",
      "How many unique species are duplicated?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = observations.groupby([\"park_name\", \"scientific_name\"]).size().reset_index(name=\"count\")\n",
    "duplicated = grouped[grouped[\"count\"] > 1]\n",
    "print(\"Amount of duplicated observations in each park:\")\n",
    "print(duplicated.groupby(\"park_name\").size())\n",
    "print(\"\")\n",
    "print(\"Are some species duplicated more than once? Let us see the maximum duplication number.\")\n",
    "print(duplicated[\"count\"].max())\n",
    "print(\"\")\n",
    "print(\"How many unique species are duplicated?\")\n",
    "duplicated.scientific_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [206]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mduplicated\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspecies_cleaned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minner\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscientific_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m spiecies_duplicated \u001b[38;5;241m=\u001b[39m result[result\u001b[38;5;241m.\u001b[39mduplicated(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscientific_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpark_name\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(spiecies_duplicated)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:9976\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[0;32m   9813\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin\u001b[39m(\n\u001b[0;32m   9814\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   9815\u001b[0m     other: DataFrame \u001b[38;5;241m|\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[DataFrame \u001b[38;5;241m|\u001b[39m Series],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9821\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   9822\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   9823\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   9824\u001b[0m \u001b[38;5;124;03m    Join columns of another DataFrame.\u001b[39;00m\n\u001b[0;32m   9825\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9974\u001b[0m \u001b[38;5;124;03m    5  K1  A5   B1\u001b[39;00m\n\u001b[0;32m   9975\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 9976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_join_compat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlsuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrsuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9982\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9984\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:10015\u001b[0m, in \u001b[0;36mDataFrame._join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[0;32m  10005\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  10006\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[0;32m  10007\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10008\u001b[0m             other,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10013\u001b[0m             validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m  10014\u001b[0m         )\n\u001b[1;32m> 10015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  10016\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10018\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m  10021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m  10022\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlsuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrsuffix\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10023\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10024\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  10025\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  10026\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m  10027\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 110\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:707\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    699\u001b[0m (\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m    703\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 707\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1340\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1334\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1336\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1337\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1338\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1339\u001b[0m     ):\n\u001b[1;32m-> 1340\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1342\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "result = duplicated.join(species_cleaned, how=\"inner\", on=\"scientific_name\")\n",
    "spiecies_duplicated = result[result.duplicated(subset=[\"scientific_name\", \"park_name\"])].groupby(\"category\").size()\n",
    "print(spiecies_duplicated)\n",
    "original_species_nr = species_cleaned.groupby(\"category\").size()\n",
    "spiecies_duplicated_percent = spiecies_duplicated\n",
    "for row in original_species_nr.keys():\n",
    "    if row in spiecies_duplicated_percent.keys():\n",
    "        spiecies_duplicated_percent[row] = spiecies_duplicated_percent[row]/original_species_nr[row]*100\n",
    "    else:\n",
    "        spiecies_duplicated_percent[row] = 0\n",
    "\n",
    "spiecies_duplicated_percent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
